\chapter{基于深度卷积网络的线虫轮廓解析}
\section{引言}
	多线虫跟踪问题中，多线虫轮廓之间相互遮挡是造成线虫跟踪丢失的主要原因，是实现线虫长期跟踪的关键。
	如图\ref{fig:multiworm}所示，是一张经过前景轮廓提取后得到的一幅二值化图片，图中线虫轮廓之间出现严重的相互遮挡的情况
	。虽然人眼可以很轻松的辨别出图中所有单个线虫的轮廓，但自动化地线虫轮廓解析却十分困难，尽管深度学习在图像分割任务中取得了很大的成功，
	但线虫轮廓的解析不同于图像分割，因此不能直接转为一个端到端的学习问题。
	本文提出了一种基于深度卷积网络的线虫轮廓解析的方法尝试解决这一问题，并探讨了多种网络结构的设计对识别性能的影响。
	\begin{figure}[h]
	  \centering
	  \includegraphics[width=7cm]{figure/chap4/multi-worm.jpg}
	  \bicaption[这里将出现在插图索引中]
		{多线虫轮廓相互遮挡图片}
		{Change in contour curvature}
	  \label{fig:multiworm}
	\end{figure}

\section{线虫轮廓解析方法介绍}
	本文提出的线虫轮廓解析方法的关键在于设计了一个只对位于图片中央的线虫轮廓敏感的神经网络，而对非图片中央位置的线虫轮廓不敏感。当输入
	一幅包含多线虫轮廓的前景图像时，网络的输出为中央线虫轮廓的图像。
	形式化的描述如下：假设一幅图片中包含N个线虫轮廓，定义一个集合$E =\{e_0,e_1,\dots,e_N\}$,其中$e_0$表示轮廓位于图片
	中央的线虫，$e_i$包含线虫重心坐标、轮廓以及方向等信息。$I(E)=R(\{e_0,e_1,\dots,e_N\};\xi)$表示由集合E渲染得到的包含N个线虫的图片，R表示
	渲染函数，$\xi$表示随机噪声。$I(E_0)=R(\{e_0\};\xi)$表示由中间线虫渲染得到的图片。我们希望得到这样的映射
	$S:I(E)\rightarrow I(E_0)$，映射函数$S$通过一个深度卷积网络加以实现，本文将其命名为SingleOut-net网络。
	\begin{figure}[htb]
	  \centering
	  \includegraphics[width=9cm]{figure/chap4/flow.jpg}
	  \bicaption[这里将出现在插图索引中]
		{多线虫轮廓相互遮挡图片}
		{Change in contour curvature}
	  \label{fig:chap4:flow}
	\end{figure}
	
	如图\ref{fig:chap4:flow}是本文提出的线虫轮廓解析方法的主要流程。首先假定从前景提取的步骤中已经得到
	包含多线虫轮廓的二值化图像如图\ref{fig:multiworm}所示，在该二值化图像的前景像素中(即非零值像素)产生足够多的随机点使得每个线虫轮廓上至少
	包含一个随机点。然后以这些随机像素点为中心在原图中抠出固定尺寸的图像块，将这些图像块输入到训练好的SingleOut-Net
	网络从而得到中央线虫的轮廓。由于在随机点产生阶段，同一个线虫轮廓包含不止一个随机点。因此由SingleOut-Net网络输出
	的线虫轮廓包含同一个线虫的多个轮廓，在原图像坐标中，同一个线虫的多个轮廓是重合的。通过滤除掉重复的线虫轮廓以及
	不完整的轮廓，最终可以得到解析的结果。算法\ref{algo:worm_parser}描述线虫轮廓解析的整个算法实现。
\begin{algorithm}
\caption{线虫轮廓解析算法}
\label{algo:worm_parser}
\begin{algorithmic}[1]
\Require $Worm\_data$双重列表，$Worm\_data[i][j]$表示第$i$帧图像中第$j$只线虫。
\Ensure 输出$trackID$
  \algstore{MergeSort}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\begin{algorithmic}[1]
  \algrestore{MergeSort}
\Function {Parser\_Worm}{$Worm\_Image$}
		\State $Seed\_points \gets Generate\_seed\_points(Worm\_Image)$
		\State $Image\_Patchs \gets Crop\_Image(Worm\_Image,Seed\_points)$
		\State $SingleOut\_OutputImages \gets []$
		\For{$i = 0 \to Image\_Patchs.length-1$}
			\State $SingleOut\_OutputImages[i] \gets SingleOut\_Net(Image\_Patchs[i])$
			\State $SingleOut\_OutputImages[i] \gets Post\_ProcessImage(SingleOut\_OutputImages[i])$
		\EndFor
		\State $Worm\_Contours \gets Extracte\_WormContour(SingleOut\_OutputImages)$
		\State $resulte \gets Filter\_WormContour(Worm\_Contours)$
		\State \Return $resulte$
\EndFunction
\end{algorithmic}
\end{algorithm}
		\begin{figure}[htp]
	  \centering
	  \includegraphics[width=9cm]{figure/chap4/rand_seed.png}
	  \bicaption[这里将出现在插图索引中]
		{多线虫轮廓相互遮挡图片}
		{Change in contour curvature}
	  \label{fig:chap4:rand_seed}
	\end{figure}
\subsection{随机点的产生}
	随机点的产生直接影响线虫轮廓解析方法的效率，随机点的数量过大导致SingleOut-Net网络需要对大量的图像块处理，需要很大
	的计算量，从而导致解析一帧图像需要大量的时间。但随机点的数量太少，可能导致有些线虫的轮廓上没有随机点，这些线虫的
	轮廓将得不到解析。实验发现，直接在原图像中生成随机点的方式非常的低效，主要是因为前景像素只占原图中总像素的一小部分。
	大部分的随机点落在了背景里。本文提出一种高效的随机点产生方法。首先，找出原图中所有的轮廓，然后在每个轮廓的边上等距
	的采样一定数量的边界点，最后在边界点的邻域内再采样。这种随机点产生的方法只需要产生少量的随机点即可覆盖所有的
	线虫轮廓，最终采样的结果如图\ref{fig:chap4:rand_seed}所示。

\subsection{SingleOut-Net网络输出后处理}
	图\ref{fig:chap4:singleout}显示了利用训练好的SingleOut-Net网络对部分图像块处理的结果。从图中可以看出SingleOut-Net
	网络成功的将位于图片中央的线虫轮廓从周围的线虫轮廓中分离出来。经过二值化等后处理步骤后，再用轮廓提取算法即可得到所有图像块
	对应的中央线虫的轮廓。
	但由于在随机点生成的过程中同一个线虫轮廓上可能包含
	多个随机点。所以在SingleOut-Net输出的结果中，同一个线虫的轮廓可能出现了多次。通过计算两个线虫轮廓在原图坐标中面积的
	重合度，当两个轮廓的重合度大于一个设定的阈值时，则只需保留其中的一个轮廓。当一个轮廓完全被另一个轮廓包含时，则保留
	轮廓面积较大的轮廓。过滤掉重复的轮廓以及不完整的轮廓后即可得到解析的结果，最终的解析结果如图\ref{fig:chap4:parser}
	所示。
	\begin{figure}[htb]
	  \centering
	  \includegraphics[width=8cm]{figure/chap4/singleout.jpg}
	  \bicaption[这里将出现在插图索引中]
		{多线虫轮廓相互遮挡图片}
		{Change in contour curvature}
	  \label{fig:chap4:singleout}
	\end{figure}
	\begin{figure}[htb]
	  \centering
	  \includegraphics[width=7cm]{figure/chap4/Parser_Worms5.jpg}
	  \bicaption[这里将出现在插图索引中]
		{多线虫轮廓相互遮挡图片}
		{Change in contour curvature}
	  \label{fig:chap4:parser}
	\end{figure}
\section{SingleOut-net网络设计及模型评估}
	\begin{figure}[htb]
	  \centering
	  \includegraphics[width=11cm]{figure/chap4/dataset.jpg}
	  \bicaption[这里将出现在插图索引中]
		{多线虫轮廓相互遮挡图片}
		{Change in contour curvature}
	  \label{fig:chap4:dataset}
	\end{figure}
\subsection{数据集的制作}
\label{dataset}
	SingleOut-Net网络的训练需要大量的标定的数据集，本文采用了人工生成的数据集来训练网络的参数。
	数据集的制作流程如图\ref{fig:chap4:dataset}所示。
	BBBC010数据集\cite{Ljosa2012Annotated}中包含1407张单线虫轮廓的图像。首先，我们从BBBC010数据集中
	提取所有单线虫的轮廓得到一个单线虫的轮廓库。然后从单线虫的轮廓库中随机地选取一个线虫轮廓在一个
	分辨率为$256\times256$的背景图(像素值全为零)的中央画出。这一步得到的图作为网络训练的标签。继续从
	线虫轮廓库中随机选取若干个线虫的轮廓并在标签图像中随机的画出。至此，便得到了SingleOut网络的输入以及对应的
	标签。为了加快网络的收敛速度，本文将数据集的输入以及对应的输出归一化到$0\sim1$并加入一定量的高斯白噪声。
	通常数据集的多样性可以使神经网络学习到更多的模式，从而使网络具有更好的泛化能力。
	为了进一步增强数据集的多样性，本文对每个随机选取的单线虫轮廓进行随机的缩放和随机的旋转。

\subsection{网络结构的设计}
\label{archtecture}
\begin{figure}[htb]
	  \centering
	  \includegraphics[width=14cm]{figure/chap4/arch1.jpg}
	  \bicaption[这里将出现在插图索引中]
		{多线虫轮廓相互遮挡图片}
		{Change in contour curvature}
	  \label{fig:chap4:netarch}
	\end{figure}
	如图\ref{fig:chap4:netarch}所示是SingleOut-Net的网络结构。输入为$256\times256\times1$的张量，输出也为
	相同尺寸的张量。整个网络架构由两个模块级联构成。第一个模块为一个类似于U-Net网络\cite{ronneberger2015u}的卷积模块在整个网络架构中
	相当于一个编码器，图中每个方块都表示上一章介绍的残差连接单元。第一个模块包含两条路径，分别为降采样路径和
	上采样路径。降采样路径上每经过一个残差连接模块后面都连接一个降采样层，将输入张量的尺寸减小一倍同时将通道数扩大一倍。
	降采样层通过一个卷积层实现,其卷积核的大小为$2\times2$步长为2。卷积后紧跟着的是Batch Normalization 层
	和激活函数层。由于Relu函数\cite{xu2015empirical}具有克服梯度消失和加快网络的收敛等优势，这里使用了Relu激活函数。
	上采样路径与降采样路径类似，只不过将降采样层换成上采样层。上采样层通过反卷积实现，其卷积核大小为$2\times2$步长为2。
	如图\ref{fig:chap4:netarch}所示，上采样层的输入由两部分构成，分别为降采样路径中相同分别率的张量和上采样路径中前面的
	张量。第二个模块为一个PixelCNN网络\cite{van2016conditional}模块作为解码器。PixelCNN网络由Deepmind于2016年提出并用于
	条件图像生成。可以生成非常逼真的图像。本文将其应用在SingleOut网络中作为解码器来生成线虫图像。最后通过一个$1\times1$
	的卷积将通道数变为输出图像的通道数，并通过Sigmoid激活函数将输出的数值限制在$0\sim1$范围内。最终的输出是一个通道数为1
	的概率图。概率图中每一个像素值的大小表示该像素属于中央线虫轮廓的概率。

\subsection{损失函数及评价指标}
	
\subsubsection{评价指标}
	为了更好的对不同的网络架构进行量化分析和性能比较，因此需要选取一些评价指标。本文提出的SingleOut-Net网络
	用于判别图像中每个像素是否属于中央线虫轮廓像素，所以是一个像素二分类网络。本文将像素分类误差作为网络评价指标，
	像素分类误差由公式\ref{eq:metrics}表示。
	\begin{equation}
		pixel\_cls\_error =1- \frac{number\_of\_corrected\_classified\_pixels}{total\_number\_of\_pixels} \label{eq:metrics}
	\end{equation}
\subsection{网络的训练}
	
	根据\ref{dataset}节介绍的数据集生成方法，可以生成任意大小的训练集。但为了节省内存开销，本文采用了训练集动态生成的方法
	，即在训练阶段每个minibatch的样本图片都是动态生成的。但动态生成训练样本需要一定的时间开销，从而使网络训练时间变长。为了缩短网络训练时间以及在限定
	时间探索更优的网络架构，本文将数据生成和网络训练这两个任务并行，即用一个专门的线程负责数据集的生成。另外为了比较
	不同的网络架构的性能，测试集的样本应该保持不变，而本文中的数据集是动态随机生成的。为了获得一个不变的测试集，在网络训练和模型测试阶段，本文分别采用了
	两个不同的随机数种子初始化随机数生成器。
	
	神经网络模型的训练分为前向传播、反向传播和权值更新三个步骤。batchsize作为一个重要的超参数，其决定将多少样本作为一个整体估计梯度下降的方向。如果将其设置得过大，
	会导致网络模型很难跳出局部最小值点。如果设置得过小，则很难获得一个准确的梯度下降方向，在本文中batchsize的
	大小为4。神经网络的优化算法大致可以分为三大类：基于一阶微分的最优化方法(随机梯度下降)、基于二阶微分
	的最优化方法(牛顿法)以及基于二阶微分近似的方法(AdaDelta算法\cite{zeiler2012adadelta}和Adam算法\cite{kinga2015method}等)。随机梯度下降的最优化方法计算量
	最小，但网络的收敛速度慢。牛顿法由于利用了二阶信息，与其他的最优化方法相比具有更好的收敛性能，但由于要计算
	Hessian矩阵所以计算量很大。于是研究者们提出了很多基于二阶微分的近似方法，这些最优化方法是计算量和
	收敛性能的一个折中。本文采用了Adam最优化方法优化网络模型并将学习率设置为0.0002。训练40个epoch(每个epoch
	包含1000个batch)后网络已经完全收敛，图\ref{fig:chap4:loss}表示损失函数随epoch数的增加而下降，经过 20个epoch后
	网络已经基本收敛。
	\begin{figure}[thb]
	  \centering
	  \includegraphics[width=13cm]{figure/chap4/loss.jpg}
	  \bicaption[这里将出现在插图索引中]
		{网络训练过程中损失函数的变化}
		{Change in contour curvature}
	  \label{fig:chap4:loss}
	\end{figure}
	
	为了观察网络训练过程中SingleOut-Net网络性能的变化，本文对网络每隔100次迭代进行一次测试，图\ref{fig:chap4:progress}
	显示了网络训练过程中对模型测试的结果。从图中可以看出随着网络模型迭代次数的增加SingleOut-Net网络逐渐学会过滤掉非中央
	线虫的轮廓，只保留中央线虫的轮廓。
		\begin{figure}[htb]
	  \centering
	  \includegraphics[width=15cm]{figure/chap4/progress.jpg}
	  \bicaption[这里将出现在插图索引中]
		{网络训练过程中模型测试结果}
		{Change in contour curvature}
	  \label{fig:chap4:progress}
	\end{figure}
\subsection{测试结果与分析}
	 在\ref{archtecture}节，本文介绍了SingleOut-Net的网络架构，由两个模块构成编解码器结构。后端模块是一个pixelCNN，
	 相当于一个解码器的作用。为了分析这种编解码结构的网络性能，本文分别从像素误差、模型复杂度和推断时间三个方面考察了
	 pixelCNN网络模块对整个网络架构的影响。由于pixelCNN网络模块的输入和输出的尺寸保持不变，所以可以将pixelCNN模块
	 移去，然后用一个$1\times1$的卷积将编码器输出的通道数变成网络最终输出的通道数。将这种没有pixelCNN模块的网络架构
	 命名为模型一，\ref{archtecture}节介绍的网络架构命名为模型二，两个模型的性能比较如表\ref{tab:performance}所示。
	 从表中可以看出pixelCNN网络模块可以显著的降低像素误差(10倍下降)。但同时由于增加了网络的深度，使得网络在推断单张图片所消耗
	 的时间变长。
\begin{table}[!hpb]
	\centering
	\bicaption[指向一个表格的表目录索引]
    {网络模型性能的比较}
    {A Table}
	\label{tab:performance}
	\begin{tabular}{p{70pt}p{70pt}p{70pt}p{70pt}}
	\toprule
	网络模型 & 像素误差 & 模型大小 & 推断时间 \\
	\midrule
	模型一 &  0.00521\% & 46.8Mb & 31ms \\
	模型二 & 0.00045\% & 48.9Mb & 100ms \\
	\bottomrule
\end{tabular}
\end{table}
	 
\section{本章小结}
	
	


